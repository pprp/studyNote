# 深度学习阅读笔记

## 一、注意力机制

### 1.1 注意力机制原理和方法

来源：<https://blog.heuritech.com/2016/01/20/attention-mechanism/>

微信：[https://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&mid=2247485350&idx=1&sn=3e79cf2c009af1da369c8da16a9b53bb&chksm=96f375f2a184fce47f0e2459642df3ec6077b9073358dc39526b358953c4b2dd35dd41c57b67&mpshare=1&scene=23&srcid=12010TqQUvmoGFwxCOfhjkiE&sharer_sharetime=1575215773081&sharer_shareid=c16b66222c9e09eae50ae8f9081b0495#rd](#rd)

 评价：无意义

 



 

 

 

 

 

 

 

## 二、CNN模型

 

 

## 三、剪枝加速

 

 

## 四、语义分割

 

 

## 五、调参技巧

### 5.1 分类任务tricks

链接：

[https://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&mid=2247485783&idx=2&sn=10662ca037f4f2f11d9fc5854a778717&chksm=96f37b03a184f21532d223e28b4fec322a95669a7c1ea2f85f4da7f6435211b1c2cac6357a54&mpshare=1&scene=23&srcid=12017D48fUf2hqihtC3h0DFq&sharer_sharetime=1575215733637&sharer_shareid=c16b66222c9e09eae50ae8f9081b0495#rd](#rd)

code：无

评价：待尝试

#### (1) Warmup

学习率预热就是在刚开始训练的时候先使用一个较小的学习率，训练一些epoches或iterations，等模型稳定时再修改为预先设置的学习率进行训练。论文[1]中使用一个110层的ResNet在cifar10上训练时，先用0.01的学习率训练直到训练误差低于80%(大概训练了400个iterations)，然后使用0.1的学习率进行训练。

上述的方法是constant warmup，18年Facebook又针对上面的warmup进行了改进[3]，因为从一个很小的学习率一下变为比较大的学习率可能会导致训练误差突然增大。论文[3]提出了gradual warmup来解决这个问题，即从最开始的小学习率开始，每个iteration增大一点，直到最初设置的比较大的学习率。

```python
class GradualWarmupScheduler(_LRScheduler):
    """
    Args:
        mutliplier : target learnnig rate = base lr *multiplier
        total epoch : target learning rate is reached at total epoch gradually
        after scheduler: after target_epoch , use this schedueler(ReduceLROnPlateau)
    """

    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):
        self.multiplier = multiplier
        if self.multiplier <= 1.:
            raise ValueError('mutliplier should be greater than 1')
        self.total_epoch = total_epoch
        self.after_scheduler = after_scheduler
        self.finished = False
        super().__init__(optimizer)

    def get_lr(self):
        if self.last_epoch > self.total_epoch:
            if self.after_scheduler:
                if not self.finished:
                    self.after_scheduler.base_lrs = [
                        base_lr * self.multiplier for base_lr in self.base_lrs]
                    self.finished = True
                return self.after_scheduler.get_lr()
            return [base_lr * self.multiplier for base_lr in self.base_lrs]
        return [base_lr * ((self.multiplier-1.0)*self.last_epoch / self.total_epoch+1.) for base_lr in self.base_lrs]

    def step(self, epoch=None):
        if self.finished and self.after_scheduler:
            return self.after_scheduler.step(epoch)
        else:
            return super(GradualWarmupScheduler, self).step(epoch)
```

####  (2) label smooth

在分类问题中，我们的最后一层一般是全连接层，然后对应标签的one-hot编码，即把对应类别的值编码为1，其他为0。这种编码方式和通过降低交叉熵损失来调整参数的方式结合起来，会有一些问题。这种方式会鼓励模型对不同类别的输出分数差异非常大，或者说，模型过分相信它的判断。但是，对于一个由多人标注的数据集，不同人标注的准则可能不同，每个人的标注也可能会有一些错误。模型对标签的过分相信会导致过拟合。

标签平滑(Label-smoothing regularization,LSR)是应对该问题的有效方法之一，它的具体思想是降低我们对于标签的信任，例如我们可以将损失的目标值从1稍微降到0.9，或者将从0稍微升到0.1。标签平滑最早在inception-v2[4]中被提出，它将真实的概率改造为：

![1575255859418](1575255859418.png)

其中，ε是一个小的常数，K是类别的数目，y是图片的真正的标签，i代表第i个类别，q_i是图片为第i类的概率。

总的来说，LSR是一种通过在标签y中加入噪声，实现对模型约束，降低模型过拟合程度的一种正则化方法。

LSR:

```python
import torch
import torch.nn as nn
 
class NMTCritierion(nn.Module):
    """
    TODO:
    1. Add label smoothing
    """
    def __init__(self, label_smoothing=0.0):
        super(NMTCritierion, self).__init__()
        self.label_smoothing = label_smoothing
        self.LogSoftmax = nn.LogSoftmax()
 
        if label_smoothing > 0:
            self.criterion = nn.KLDivLoss(size_average=False)
        else:
            self.criterion = nn.NLLLoss(size_average=False, ignore_index=100000)
        self.confidence = 1.0 - label_smoothing
 
    def _smooth_label(self, num_tokens):
        # When label smoothing is turned on,
        # KL-divergence between q_{smoothed ground truth prob.}(w)
        # and p_{prob. computed by model}(w) is minimized.
        # If label smoothing value is set to zero, the loss
        # is equivalent to NLLLoss or CrossEntropyLoss.
        # All non-true labels are uniformly set to low-confidence.
        one_hot = torch.randn(1, num_tokens)
        one_hot.fill_(self.label_smoothing / (num_tokens - 1))
        return one_hot
 
    def _bottle(self, v):
        return v.view(-1, v.size(2))
 
    def forward(self, dec_outs, labels):
        scores = self.LogSoftmax(dec_outs)
        num_tokens = scores.size(-1)
 
        # conduct label_smoothing module
        gtruth = labels.view(-1)
        if self.confidence < 1:
            tdata = gtruth.detach()
            one_hot = self._smooth_label(num_tokens)  # Do label smoothing, shape is [M]
            if labels.is_cuda:
                one_hot = one_hot.cuda()
            tmp_ = one_hot.repeat(gtruth.size(0), 1)  # [N, M]
            tmp_.scatter_(1, tdata.unsqueeze(1), self.confidence)  # after tdata.unsqueeze(1) , tdata shape is [N,1]
            gtruth = tmp_.detach()
        loss = self.criterion(scores, gtruth)
        return loss
```

LSR2:

```python
import torch
import torch.nn as nn
class LabelSmoothSoftmaxCE(nn.Module):
    def __init__(self,
                 lb_pos=0.9,
                 lb_neg=0.005,
                 reduction='mean',
                 lb_ignore=255,
                 ):
        super(LabelSmoothSoftmaxCE, self).__init__()
        self.lb_pos = lb_pos
        self.lb_neg = lb_neg
        self.reduction = reduction
        self.lb_ignore = lb_ignore
        self.log_softmax = nn.LogSoftmax(1)

    def forward(self, logits, label):
        logs = self.log_softmax(logits)
        ignore = label.data.cpu() == self.lb_ignore
        n_valid = (ignore == 0).sum()
        label[ignore] = 0
        lb_one_hot = logits.data.clone().zero_().scatter_(1, label.unsqueeze(1), 1)
        label = self.lb_pos * lb_one_hot + self.lb_neg * (1-lb_one_hot)
        ignore = ignore.nonzero()
        _, M = ignore.size()
        a, *b = ignore.chunk(M, dim=1)
        label[[a, torch.arange(label.size(1)), *b]] = 0

        if self.reduction == 'mean':
            loss = -torch.sum(torch.sum(logs*label, dim=1)) / n_valid
        elif self.reduction == 'none':
            loss = -torch.sum(logs*label, dim=1)
        return loss


if __name__ == '__main__':
    torch.manual_seed(15)
    criterion = LabelSmoothSoftmaxCE(lb_pos=0.9, lb_neg=5e-3)
    
    out = torch.randn(10, 5).cuda()
    lbs = torch.randint(5, (10,)).cuda()
    print('out:', out)
    print('lbs:', lbs)

    import torch.nn.functional as F
    
    loss = criterion(out, lbs)
    print('loss:', loss)
```

LSR3:

```python
class LSR(nn.Module):
    def __init__(self, e=0.1, reduction='mean'):
        super().__init__()
        self.log_softmax = nn.LogSoftmax(dim=1)
        self.e = e
        self.reduction=reduction
    def _one_hot(self, labels, classes, value=1):
        """
        convert labels to one hot vectors
        args:
            labels: torch tensor [label1, label2...]
            classes: int, num of classes
            value: label value in one hot value, defalt to 1
        return:
            return one hot format labels in shape[bs, classes]
        """
        one_hot = torch.zeros(labels.size()[0], classes)
        labels = labels.view(labels.size()[0],-1)
        value_added = torch.Tensor(labels.size()[0], 1).fill_(value)
        
        value_added = value_added.to(labels.device)
        one_hot = one_hot.to(labels.device)

        one_hot.scatter_add_(1, labels, value_added)
        return one_hot
    def _smooth_label(self, target, length, smooth_factor):
        """
        args:
            targets: formate [label1, label2, label_batch size]
            length: length of one-hot format (num of classes)
            smooth facter: smooth factor
        """
        one_hot = self._one_hot(target, length, value=1-smooth_factor)
        one_hot += smooth_factor / length
        return one_hot.to(target.device)

```

#### (3) Linear scaling learning rate

Linear scaling learning rate是在论文[3]中针对比较大的batch size而提出的一种方法。

在凸优化问题中，随着批量的增加，收敛速度会降低，神经网络也有类似的实证结果。随着batch size的增大，处理相同数据量的速度会越来越快，但是达到相同精度所需要的epoch数量越来越多。也就是说，使用相同的epoch时，大batch size训练的模型与小batch size训练的模型相比，验证准确率会减小。

上面提到的gradual warmup是解决此问题的方法之一。另外，linear scaling learning rate也是一种有效的方法。在mini-batch SGD训练时，梯度下降的值是随机的，因为每一个batch的数据是随机选择的。增大batch size不会改变梯度的期望，但是会降低它的方差。也就是说，大batch size会降低梯度中的噪声，所以我们可以增大学习率来加快收敛。

具体做法很简单，比如ResNet原论文[1]中，batch size为256时选择的学习率是0.1，当我们把batch size变为一个较大的数b时，学习率应该变为 0.1 × b/256

#### (4) Random image cropping and patching

Random image cropping and patching (RICAP)[7]方法随机裁剪四个图片的中部分，然后把它们拼接为一个图片，同时混合这四个图片的标签。

![1575256732415](1575256732415.png)

如下图所示，Ix, Iy是原始图片的宽和高。w和h称为boundary position，它决定了四个裁剪得到的小图片的尺寸。w和h从beta分布Beta(β, β)中随机生成，β也是RICAP的超参数。最终拼接的图片尺寸和原图片尺寸保持一致。

```python
beta = 0.3

for (images, targets) in data_loader:
    # get image size
    I_x, I_y = images.size()[2:]
    # draw a boundary position w,h
    # draw a boundry position (w, h)
    w = int(np.round(I_x * np.random.beta(beta, beta)))
    h = int(np.round(I_y * np.random.beta(beta, beta)))
    w_ = [w, I_x - w, w, I_x - w]
    h_ = [h, h, I_y - h, I_y - h]
    # select and crop four images
    cropped_images = {}
    c_ = {}
    W_ = {}
    for k in range(4):
        index = torch.randperm(images.size(0))
        x_k = np.random.randint(0, I_x - w_[k] + 1)
        y_k = np.random.randint(0, I_y - h_[k] + 1)
        cropped_images[k] = images[index][:, :,
                                          x_k:x_k + w_[k], y_k:y_k + h_[k]]
        c_[k] = target[index].cuda()
        W_[k] = w_[k] * h_[k] / (I_x * I_y)
        # patch cropped images
        patched_images = torch.cat(
            (torch.cat((cropped_images[0], cropped_images[1]), 2), 
            torch.cat((cropped_images[2], cropped_images[3]), 2)), 3)
        patched_images = patched_images.cuda()
        # get output
        output = model(patched_images)
        # calculate loss and accuracy
        loss = sum([W_[k] * criterion(output, c_[k]) for k in range(4)])
        acc = sum([W_[k] * accuracy(output, c_[k])[0] for k in range(4)])

```

#### (5) 知识蒸馏

提高几乎所有机器学习算法性能的一种非常简单的方法是在相同的数据上训练许多不同的模型，然后对它们的预测进行平均。但是使用所有的模型集成进行预测是比较麻烦的，并且可能计算量太大而无法部署到大量用户。Knowledge Distillation(知识蒸馏)[8]方法就是应对这种问题的有效方法之一。

在知识蒸馏方法中，我们使用一个教师模型来帮助当前的模型（学生模型）训练。教师模型是一个较高准确率的预训练模型，因此学生模型可以在保持模型复杂度不变的情况下提升准确率。比如，可以使用ResNet-152作为教师模型来帮助学生模型ResNet-50训练。在训练过程中，我们会加一个蒸馏损失来惩罚学生模型和教师模型的输出之间的差异。

给定输入，假定p是真正的概率分布，z和r分别是学生模型和教师模型最后一个全连接层的输出。之前我们会用交叉熵损失l(p,softmax(z))来度量p和z之间的差异，这里的蒸馏损失同样用交叉熵。所以，使用知识蒸馏方法总的损失函数是

![1575259852786](1575259852786.png)

上式中，第一项还是原来的损失函数，第二项是添加的用来惩罚学生模型和教师模型输出差异的蒸馏损失。其中，T是一个温度超参数，用来使softmax的输出更加平滑的。实验证明，用ResNet-152作为教师模型来训练ResNet-50，可以提高后者的准确率。

#### (6) Cutoff

Cutout[9]是一种新的正则化方法。原理是在训练时随机把图片的一部分减掉，这样能提高模型的鲁棒性。它的来源是计算机视觉任务中经常遇到的物体遮挡问题。通过cutout生成一些类似被遮挡的物体，不仅可以让模型在遇到遮挡问题时表现更好，还能让模型在做决定时更多地考虑环境(context)。

```python
import torch 
import numpy as np 
class Cutout(object): 
    """Randomly mask out one or more patches from an image.
    Args:n_holes (int): 
        Number of patches to cut out of each image. 
        length (int): The length (in pixels) of each square patch. 
    """ 
    def __init__(self, n_holes, length): 
        self.n_holes = n_holes self.length = length 
        
    def __call__(self, img): 
        """ Args:img (Tensor): 
                Tensor image of size (C, H, W). 
            Returns: 
                Tensor: Image with n_holes of dimension length x length cut out of it. 
        """ 
        h = img.size(1) w = img.size(2) 
        mask = np.ones((h, w), np.float32)
        for n in range(self.n_holes):
            y = np.random.randint(h) 
            x = np.random.randint(w) 
            y1 = np.clip(y - self.length // 2, 0, h) 
            y2 = np.clip(y + self.length // 2, 0, h) 
            x1 = np.clip(x - self.length // 2, 0, w) 
            x2 = np.clip(x + self.length // 2, 0, w) 
            mask[y1: y2, x1: x2] = 0. 

        mask = torch.from_numpy(mask) 
        mask = mask.expand_as(img) 
        img = img * mask 
        return img
```

#### (7) Random erasing 

Random erasing[6]其实和cutout非常类似，也是一种模拟物体遮挡情况的数据增强方法。区别在于，cutout是把图片中随机抽中的矩形区域的像素值置为0，相当于裁剪掉，random erasing是用随机数或者数据集中像素的平均值替换原来的像素值。而且，cutout每次裁剪掉的区域大小是固定的，Random erasing替换掉的区域大小是随机的。

#### (8) Cosine learning rate decay

在warmup之后的训练过程中，学习率不断衰减是一个提高精度的好方法。其中有step decay和cosine decay等，前者是随着epoch增大学习率不断减去一个小的数，后者是让学习率随着训练过程曲线下降。

对于cosine decay，假设总共有T个batch（不考虑warmup阶段），在第t个batch时，学习率η_t为：
  ![1575260997571](1575260997571.png)

这里，η代表初始设置的学习率。这种学习率递减的方式称之为cosine decay。

下面是带有warmup的学习率衰减的可视化图[4]。其中，图(a)是学习率随epoch增大而下降的图，可以看出cosine decay比step decay更加平滑一点。图(b)是准确率随epoch的变化图，两者最终的准确率没有太大差别，不过cosine decay的学习过程更加平滑。

![1575261028733](1575261028733.png)

 

#### (9) Mixup training

Mixup[10]是一种新的数据增强的方法。Mixup training，就是每次取出2张图片，然后将它们线性组合，得到新的图片，以此来作为新的训练样本，进行网络的训练，如下公式，其中x代表图像数据，y代表标签，则得到的新的$\hat{x}, \hat{y}$。

$$
\hat{x} = \lambda x_i+(1-\lambda)x_j, \\
\hat{y} = \lambda y_i+(1-\lambda)y_j
$$

其中，λ是从Beta(α, α)随机采样的数，在[0,1]之间。在训练过程中，仅使用(xhat, yhat)。

Mixup方法主要增强了训练样本之间的线性表达，增强网络的泛化能力，不过mixup方法需要较长的时间才能收敛得比较好。

Mixup代码如下：

```python
## mixup
for (images, labels) in train_loader:
    l = np.random.beta(mixup_alpha, mixup_alpha) 
    index = torch.randperm(images.size(0)) 
    images_a, images_b = images, images[index] 
    labels_a, labels_b = labels, labels[index] 
    mixed_images = l * images_a + (1 - l) * images_b 
    outputs = model(mixed_images) 
    loss = l * criterion(outputs, labels_a) + (1 - l) * criterion(outputs, labels_b) 
    acc = l * accuracy(outputs, labels_a)[0] + (1 - l) * accuracy(outputs, labels_b)[0]

```

#### (10) adabound

AdaBound是最近一篇论文[5]中提到的，按照作者的说法，AdaBound会让你的训练过程像adam一样快，并且像SGD一样好。

如下图所示，使用AdaBound会收敛速度更快，过程更平滑，结果更好。

![1575261394997](1575261394997.png)

另外，这种方法相对于SGD对超参数的变化不是那么敏感，也就是说鲁棒性更好。但是，针对不同的问题还是需要调节超参数的，只是所用的时间可能变少了。

![1575261432431](1575261432431.png)

当然，AdaBound还没有经过普遍的检验，也有可能只是对于某些问题效果好。

使用方法如下： 安装AdaBound

```
pip install adabound
```

使用AdaBound(和其他PyTorch optimizers用法一致)

```
optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)
```

#### (11) Auto Augment

数据增强在图像分类问题上有很重要的作用，但是增强的方法有很多，并非一股脑地用上所有的方法就是最好的。那么，如何选择最佳的数据增强方法呢？ AutoAugment[11]就是一种搜索适合当前问题的数据增强方法的方法。该方法创建一个数据增强策略的搜索空间，利用搜索算法选取适合特定数据集的数据增强策略。此外，从一个数据集中学到的策略能够很好地迁移到其它相似的数据集上。

AutoAugment在cifar10上的表现如下表，达到了98.52%的准确率。

![1575261560910](1575261560910.png)

#### (12) other

**常用的正则化方法为**

- Dropout
- L1/L2正则
- Batch Normalization
- Early stopping
- Random cropping
- Mirroring
- Rotation
- Color shifting
- PCA color augmentation
- ...

**其他**

- Xavier init[12]
- ...

### 5.2 目标检测tricks

arxiv: Bag of Freebies for Training Object Detection Neural Networks

1.视觉一致的Image Mixup（Visually Coherent Image Mixup for Object De- tection）

2.分类头标签平滑（Classification Head Label Smoothing）

3.数据预处理（Data Pre-processing）

主要是随机几何变换和颜色扰动。

4.训练调度程序改造（Training Scheduler Revamping）

改进学习率的衰减方法，使用cosine schedule 代替step schedule取得了更好的结果，如下图：

![1575275172068](1575275172068.png)

5.同步批归一化（Synchronized Batch Normalization）

方便多GPU训练。

6.随机形状训练（Random shapes training for single-stage object detection networks）











## 六、人脸识别

综述链接：<http://www.elecfans.com/d/709424.html>

 

 

 

## 七、模型设计

### 7.1 ACNet

From:[https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&mid=2247493985&idx=4&sn=c98ecd11cb3ed6d6f0bf827da9187708&chksm=f9a19beeced612f8b0f6fe6d78bc19d9805136cd60d376ec462dadc661fe091319be147f4698&mpshare=1&scene=23&srcid=&sharer_sharetime=1575249200518&sharer_shareid=41b434eda6085c4278d4ad01a4465363#rd](#rd)

Code:https://github.com/ShawnDing1994/ACN

Conclusion: 不太好实现,精度提升0-1%

 

**3\*3卷积+1\*3卷积+3\*1卷积=白给的精度提升**

我们提出了非对称卷积块(ACB)作为CNN的构造块，它使用一维非对称卷积核来增强方形卷积核，我们用ACBs代替标准的方形卷积核来构造一个非堆成卷积网络ACNet，该网络可以训练到更高的精度。训练后，我们等价地将ACNet转换为相同的原始架构，因此将不需要额外的计算。实验证明，ACNet可以CIFAR和ImageNet上显著提高各种经典模型的性能。

 

 ## 八、 目标检测

### 8.1 小目标检测

source: <http://bbs.cvmart.net/topics/1245?from=groupmessage>

在深度学习目标检测中，特别是人脸检测中，小目标、小人脸的检测由于**分辨率低，图片模糊，信息少，噪音多，**所以一直是一个实际且常见的困难问题。不过在这几年的发展中，也涌现了一些提高小目标检测性能的解决手段，本文对这些手段做一个分析、整理和总结。

#### 1. **传统的图像金字塔和多尺度滑动窗口检测**

最开始在深度学习方法流行之前，对于不同尺度的目标，大家普遍使用将原图build出**不同分辨率的图像金字塔**，再对每层金字塔用固定输入分辨率的分类器在该层滑动来检测目标，以求在金字塔底部检测出小目标；或者只用一个原图，在原图上，用**不同分辨率的分类器**来检测目标，以求在比较小的窗口分类器中检测到小目标。

在著名的人脸检测器 [MTCNN] (Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks)中，就使用了图像金字塔的方法来检测不同分辨率的人脸目标。

![1575275673819](1575275673819.png)

